{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_rab45JBo8HrDQ-B3sVpyQKe6G43sfTs","timestamp":1676200974565}],"authorship_tag":"ABX9TyO0dMZ/CfDcTgFrqTaZBcWJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["**Importing Dependencies**"],"metadata":{"id":"5yi-c4WoUxRj"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"P-WcMEaoK2bg","executionInfo":{"status":"ok","timestamp":1676272953600,"user_tz":-60,"elapsed":4693,"user":{"displayName":"smit Shah","userId":"11110267682582499186"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pathlib\n","import tensorflow as tf\n","import keras\n","import numpy as np\n","import pandas as pd\n","from google.colab import files\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"]},{"cell_type":"markdown","source":["**Downloading dataset**"],"metadata":{"id":"Doh8BT2JpkOR"}},{"cell_type":"code","source":["dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n","data_dir = tf.keras.utils.get_file(\"flower_photos\", origin=dataset_url, untar=True)\n","data_dir = pathlib.Path(data_dir)\n","fashion_mnist = keras.datasets.fashion_mnist\n","\n","(train_images, train_lables), (evaluating_images, evaluating_labels) = tf.keras.datasets.fashion_mnist.load_data()\n","train_images_reshaped = train_images.reshape(60000, 28, 28, 1)"],"metadata":{"id":"FuH43UBTU4Ce","executionInfo":{"status":"ok","timestamp":1676272965497,"user_tz":-60,"elapsed":11904,"user":{"displayName":"smit Shah","userId":"11110267682582499186"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ce4af39-7f7c-4865-bf5e-1aed9854f8f1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n","228813984/228813984 [==============================] - 4s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 1s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["**Functions for the task**"],"metadata":{"id":"pS1NQXYapePi"}},{"cell_type":"code","source":["def task_information():\n","  print(\"Greetings of the day..!!!\\\n","  This task usualyy focuses around the training of various models and saving all the necessary details of all the models\\\n","  into csv files. The quantity of total number of models depends on user's choice and users are allowed to tune hyperparameter\\\n","  at every layer of the individual model.  \")\n","\n","def build_model(num_layers, model_number, input_shape=(28, 28, 1)):\n","  \n","  i = 1\n","  filters = []\n","  kernel_sizes = []\n","  activations = []\n","  pooling_sizes = []\n","  paddings = []\n","\n","  epochs = int(input(\"Enter the number of epochs for Model {}: \".format(model_number)))\n","  print(\"\")\n","\n","  while i < num_layers+1:\n","    filter_value = int(input(\"Enter filter size for {} layer: \".format(i)))\n","    filters.append(filter_value)\n","\n","    kernel_size_value = int(input(\"Enter kernel size for {} layer: \".format(i)))\n","    kernel_sizes.append(kernel_size_value)\n","\n","    activation_value = input(\"Enter activation function for {} layer: \".format(i))\n","    activations.append(activation_value)\n","\n","    pooling_size_value = int(input(\"Enter pooling size for {} layer: \".format(i)))\n","    pooling_sizes.append(pooling_size_value)\n","\n","    padding_value = input(\"Enter the padding value for {} layer: \".format(i))\n","    paddings.append(padding_value)\n","\n","    print()\n","    i += 1\n","\n","  model = Sequential()\n","  model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n","\n","  for filter, kernel_size, activation, pool_size, padding, i in zip(filters, kernel_sizes, activations, pooling_sizes, paddings, range(1, num_layers+1)):\n","      model.add(Conv2D(filters=filter, kernel_size=(kernel_size,kernel_size), activation=activation, padding=padding))\n","      model.add(MaxPooling2D(pool_size=(pool_size,pool_size)))\n","\n","  model.add(Flatten())\n","  model.add(Dense(units=10, activation='softmax'))\n","  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","  history = model.fit(train_images_reshaped, train_lables, epochs = epochs, validation_split = 0.4)\n","  return history, model, epochs\n","\n","def main():\n","  task_information()\n","  print(\"\")\n","\n","  number_models = int(input(\"Please enter the number of models: \"))\n","  print(\"\")\n","\n","  dataframe = pd.DataFrame(columns=['Model Name', 'Architecture' ,'Training Accuracy', 'Validation Accuracy', 'Training Loss', 'Validation Loss', 'Epochs'])\n","\n","  i = 1\n","  while i < number_models+1:\n","    summary = []\n","    print(\"\")\n","    print(\"Enter the details of achitecture and hyperparameters for Model {}\".format(i))\n","    layers = int(input(\"Enter the layers for Model {}: \".format(i)))\n","    print(\"\")\n","    history, model, epochs = build_model(layers, i)\n","    model.summary(print_fn=lambda x: summary.append(x))\n","    dataframe.loc[i] = [model.name, summary[2:], max(history.history['accuracy']), max(history.history['val_accuracy']), min(history.history['loss']), min(history.history['val_loss']), epochs]\n","    i += 1\n","\n","  print(dataframe)\n","  dataframe.to_csv('output.csv', encoding = 'utf-8-sig', index=False) \n","  files.download('output.csv')\n"],"metadata":{"id":"mDD7KK9IhwTO","executionInfo":{"status":"ok","timestamp":1676272965498,"user_tz":-60,"elapsed":17,"user":{"displayName":"smit Shah","userId":"11110267682582499186"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":627},"id":"8Rg9G08uYust","executionInfo":{"status":"ok","timestamp":1676273031568,"user_tz":-60,"elapsed":66086,"user":{"displayName":"smit Shah","userId":"11110267682582499186"}},"outputId":"81f45590-5a7f-409d-f7cd-34f6844a787b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Greetings of the day..!!!  This task usualyy focuses around the training of various models and saving all the necessary details of all the models  into csv files. The quantity of total number of models depends on user's choice and users are allowed to tune hyperparameter  at every layer of the individual model.  \n","\n","Please enter the number of models: 1\n","\n","\n","Enter the details of achitecture and hyperparameters for Model 1\n","Enter the layers for Model 1: 1\n","\n","Enter the number of epochs for Model 1: 5\n","\n","Enter filter size for 1 layer: 32\n","Enter kernel size for 1 layer: 2\n","Enter activation function for 1 layer: relu\n","Enter pooling size for 1 layer: 4\n","Enter the padding value for 1 layer: same\n","\n","Epoch 1/5\n","1125/1125 [==============================] - 16s 5ms/step - loss: 0.9307 - accuracy: 0.7913 - val_loss: 0.4360 - val_accuracy: 0.8517\n","Epoch 2/5\n","1125/1125 [==============================] - 6s 6ms/step - loss: 0.3925 - accuracy: 0.8602 - val_loss: 0.3961 - val_accuracy: 0.8595\n","Epoch 3/5\n","1125/1125 [==============================] - 6s 5ms/step - loss: 0.3502 - accuracy: 0.8743 - val_loss: 0.3931 - val_accuracy: 0.8591\n","Epoch 4/5\n","1125/1125 [==============================] - 6s 6ms/step - loss: 0.3289 - accuracy: 0.8805 - val_loss: 0.3453 - val_accuracy: 0.8793\n","Epoch 5/5\n","1125/1125 [==============================] - 7s 6ms/step - loss: 0.3091 - accuracy: 0.8896 - val_loss: 0.3614 - val_accuracy: 0.8792\n","   Model Name                                       Architecture  \\\n","1  sequential  [ Layer (type)                Output Shape    ...   \n","\n","   Training Accuracy  Validation Accuracy  Training Loss  Validation Loss  \\\n","1           0.889611             0.879333       0.309064         0.345306   \n","\n","  Epochs  \n","1      5  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_de4b624a-eb28-4450-90b5-2c0e8b30c811\", \"output.csv\", 1310)"]},"metadata":{}}]}]}